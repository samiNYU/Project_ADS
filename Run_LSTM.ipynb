{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Run-LSTM.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Sami Abdelazim - JC Foster\n",
        "\n",
        "This notebook, ultimately, takes the multidimensional timeseries that we made in the Apply-SA_Model notebook, and applies a simple LSTM to it. Overall, we consider 3 different number of hours of lag for each datapoint, namely 6, 12, and 18. Additionally, since predicting the actual price is much more difficult than predicting if it's going up or down, we will label the data with 0 if the price went down and 1 if it went up, and perform a classification.\n",
        "\n",
        "To evaluate the performance, we calculate the accuracy (no AUC since the data is so small), additionally, we calculate how much money we would make if we used the following very simple trading strategy starting with $10000,in all cases, the number outputed would be the return on 6-18 hours of trading:\n",
        "- if we predict that the price will go up, aka 1, then we spend all of our money on oil at the current price.\n",
        "- if we predict that the price will go down, aka 0, then we sell all of our oil at the current price."
      ],
      "metadata": {
        "id": "FbcVWOQOWAUQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NQhxDKnRx4sy",
        "outputId": "95cf79f0-cf8f-4baf-8f44-6849a9a69592"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import tensorflow\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM,Dense\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('drive/MyDrive/DS-301_PROJECT/TwitterData/final_data.csv')\n",
        "X = data[['news','oil','think','gov']].values\n",
        "data['price_change'] = data[' price'] > data[' price'].shift()\n",
        "data['price_change'] = data['price_change'].apply(lambda x : 1 if x else 0)\n",
        "y = data['price_change'].values"
      ],
      "metadata": {
        "id": "ltis6CE6yErW"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "lags = [6,12,18]\n",
        "\n",
        "for lag in lags:\n",
        "  X_lag = []\n",
        "  for i in range(lag,len(y)):\n",
        "    X_lag.append(X[i-lag+1:i+1])\n",
        "\n",
        "  # define time series with lag\n",
        "  X_lag = np.asarray(X_lag)\n",
        "  y_lag = y[lag:]\n",
        "\n",
        "  tensorflow.random.set_seed(42)\n",
        "\n",
        "  trainsize = int(len(X_lag)*0.8)\n",
        "\n",
        "  #define model\n",
        "  model = Sequential()\n",
        "  model.add(LSTM(50,activation='relu',input_shape=X_lag.shape[1:]))\n",
        "  model.add(Dense(1,activation='sigmoid'))\n",
        "  model.compile(optimizer='adam',\n",
        "                loss='binary_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "  X_train = X_lag[:trainsize]\n",
        "  y_train = y_lag[:trainsize]\n",
        "\n",
        "  model.fit(X_train,y_train,epochs=10)\n",
        "  \n",
        "  # define test set\n",
        "  X_test = X_lag[trainsize:]\n",
        "  y_test = y_lag[trainsize:]\n",
        "\n",
        "  # get predictions\n",
        "  predictions = model.predict(X_test)\n",
        "  preds = []\n",
        "  predictions\n",
        "  for prediction in predictions:\n",
        "    if prediction>=0.5:\n",
        "      preds.append(1)\n",
        "    else:\n",
        "      preds.append(0)\n",
        "\n",
        "  print(f\"Accuracy for lag={lag}:\",accuracy_score(y_test,preds))\n",
        "\n",
        "  # get prices from data\n",
        "  prices = data[' price'].values\n",
        "  prices_ = prices[lag:]\n",
        "  # note start at 30 instead of 31\n",
        "  # this is so we can see how price\n",
        "  # changes from hour \n",
        "  prices_frame = prices_[trainsize-1:]\n",
        "\n",
        "  # we start with $10000\n",
        "  initial_amount = 10000\n",
        "  amount = initial_amount\n",
        "\n",
        "  for i,val in enumerate(preds):\n",
        "      if val == 1:\n",
        "        change = prices_frame[i+1]/prices_frame[i]\n",
        "        amount = amount*change\n",
        "\n",
        "  print(f\"Final Amount for lag={lag}:\", amount)\n",
        "  print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b24RQSkKL8hN",
        "outputId": "bfb10587-7426-4fe9-8aaf-1606a5161304"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "2/2 [==============================] - 2s 9ms/step - loss: 440.2448 - accuracy: 0.3095\n",
            "Epoch 2/10\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 430.6563 - accuracy: 0.3571\n",
            "Epoch 3/10\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 309.8547 - accuracy: 0.5000\n",
            "Epoch 4/10\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 384.7605 - accuracy: 0.5476\n",
            "Epoch 5/10\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 302.4201 - accuracy: 0.5238\n",
            "Epoch 6/10\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 294.8490 - accuracy: 0.5476\n",
            "Epoch 7/10\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 288.8502 - accuracy: 0.5714\n",
            "Epoch 8/10\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 279.2109 - accuracy: 0.5714\n",
            "Epoch 9/10\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 281.9002 - accuracy: 0.5952\n",
            "Epoch 10/10\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 260.6894 - accuracy: 0.5952\n",
            "Accuracy for lag=6: 0.7272727272727273\n",
            "Final Amount for lag=6: 10145.663324354902\n",
            "\n",
            "Epoch 1/10\n",
            "2/2 [==============================] - 1s 11ms/step - loss: 631.3919 - accuracy: 0.4324\n",
            "Epoch 2/10\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 553.3138 - accuracy: 0.2973\n",
            "Epoch 3/10\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 603.0826 - accuracy: 0.4865\n",
            "Epoch 4/10\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 573.8704 - accuracy: 0.4865\n",
            "Epoch 5/10\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 550.3935 - accuracy: 0.5135\n",
            "Epoch 6/10\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 525.7216 - accuracy: 0.5946\n",
            "Epoch 7/10\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 555.9365 - accuracy: 0.5946\n",
            "Epoch 8/10\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 491.0388 - accuracy: 0.6216\n",
            "Epoch 9/10\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 477.0706 - accuracy: 0.6216\n",
            "Epoch 10/10\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 536.1455 - accuracy: 0.5676\n",
            "Accuracy for lag=12: 0.8\n",
            "Final Amount for lag=12: 10257.831171861082\n",
            "\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 882.4370 - accuracy: 0.4688\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 424.5034 - accuracy: 0.4375\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 388.5302 - accuracy: 0.4375\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 412.2987 - accuracy: 0.4688\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 265.4641 - accuracy: 0.5938\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 271.4848 - accuracy: 0.5312\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 247.2979 - accuracy: 0.5938\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 269.6094 - accuracy: 0.4375\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 253.4357 - accuracy: 0.4375\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 264.5759 - accuracy: 0.3750\n",
            "Accuracy for lag=18: 0.4444444444444444\n",
            "Final Amount for lag=18: 10073.278434128326\n",
            "\n"
          ]
        }
      ]
    }
  ]
}